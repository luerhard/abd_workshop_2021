{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Introduction to NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/602/1*bx85lgIdG9PWdCCnfNpsjQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Key Terminology:\n",
    "\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    Named Entity Recognition (NER)\n",
    "    \n",
    "    Information Extraction (IE)\n",
    "    \n",
    "    Gazetteer (Rules-Based Method)\n",
    "    \n",
    "    Linguistic Ambiguity\n",
    "    \n",
    "    Domain Adaptation\n",
    "    \n",
    "    Generalize\n",
    "\n",
    "\n",
    "\n",
    "Key Libraries:\n",
    "\n",
    "    NLP           ==> spaCy & NLTK\n",
    "    \n",
    "    Word Vectors  ==> Gensim\n",
    "\"\"\"\n",
    "\n",
    "# images\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/602/1*bx85lgIdG9PWdCCnfNpsjQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Gazetteer and NER (Rules-Based NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('''http://www.pauladaunt.com/books/Children's/Harry_Potter1-4/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt''')\n",
    "hp = r.content.decode('utf-8')\n",
    "print(hp[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://query.wikidata.org/#SELECT%20%3Fitem%20%3FitemLabel%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP1441%20wd%3AQ8337.%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ3658341.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ron Weasley', 'Hermione Granger', 'Lord Voldemort',\n",
       "       'Severus Snape', 'Rubeus Hagrid', 'Draco Malfoy', 'Ginny Weasley',\n",
       "       'Luna Lovegood', 'Neville Longbottom', 'Minerva McGonagall'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#fetching data from Wikidata\n",
    "\n",
    "##catching empty labels\n",
    "def try2unpack(x):\n",
    "    try:\n",
    "        x=x['value']\n",
    "    except (KeyError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if 'http://www.wikidata.org/entity/Q' in x or 'http://www.wikidata.org/entity/P' in x:\n",
    "            return x.rsplit('/',1)[1]\n",
    "        else:\n",
    "            return x\n",
    "    except TypeError:\n",
    "        return x\n",
    "\n",
    "##convert fetched data to dataframe\n",
    "def json2pandas(data):\n",
    "    return pd.DataFrame(data['results']['bindings'], columns=data['head']['vars']).applymap(lambda x: try2unpack(x))\n",
    "\n",
    "##example query    \n",
    "url = 'https://query.wikidata.org/sparql'\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?item ?itemLabel \n",
    "WHERE \n",
    "{\n",
    "  ?item wdt:P1441 wd:Q8337.\n",
    "  ?item wdt:P31 wd:Q3658341.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "\"\"\".strip()\n",
    "r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "if (r.status_code == 414 | r.status_code == 431 ):\n",
    "    r = requests.post(url, params = {'format': 'json', 'query': query})\n",
    "status=r.status_code\n",
    "data = r.json()\n",
    "characters=json2pandas(data)\n",
    "characters = characters['itemLabel'].values\n",
    "characters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "nearly twice the usual amount of neck, which came in very useful as she\n",
      "spent so much of her time craning over garden fences, spying on the\n",
      "neighbors. The Dursleys had a small son called Dudley and in their\n",
      "opinion there was no finer boy anywhere.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mr Dursley was the director of a firm called Grunnings which made drills He was a big beefy man with hardly any neck although he did have a very large mustache Mrs Dursley was thin and blonde and had nearly twice the usual amount of neck which came in very useful as she spent so much of her time craning over garden fences spying on the neighbors The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = hp.split('\\n\\n')[4]\n",
    "\n",
    "print(text)\n",
    "text = text.replace(\"\\n\", \" \").strip()\n",
    "text = re.sub('[^\\w ]+','', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr', 'Dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'Grunnings', 'which', 'made', 'drills', 'He', 'was', 'a', 'big', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', 'Mrs', 'Dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', 'spying', 'on', 'the', 'neighbors', 'The', 'Dursleys', 'had', 'a', 'small', 'son', 'called', 'Dudley', 'and', 'in', 'their', 'opinion', 'there', 'was', 'no', 'finer', 'boy', 'anywhere']\n"
     ]
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    if word in characters:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ron', 'Weasley', 'Hermione', 'Granger', 'Lord']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_names = []\n",
    "for character in characters:\n",
    "    names = character.split()\n",
    "    for name in names:\n",
    "        character_names.append(name.strip())\n",
    "character_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dursley\n",
      "the\n",
      "Dursley\n",
      "the\n",
      "the\n",
      "The\n",
      "Dudley\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in character_names:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Character: Mr Dursley\n",
      "Found Character: Mrs Dursley\n",
      "Found Character: Dudley\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mr Dursley was the director of a firm called Grunnings which made drills He was a big beefy man with hardly any neck although he did have a very large mustache Mrs Dursley was thin and blonde and had nearly twice the usual amount of neck which came in very useful as she spent so much of her time craning over garden fences spying on the neighbors The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['The', 'the']\n",
    "i = 0\n",
    "for word in words:\n",
    "    if word in character_names and word not in stopwords:\n",
    "        if words[i-1][0].isupper():\n",
    "            print(f\"\"\"Found Character: {words[i-1]} {word}\"\"\")\n",
    "        else:\n",
    "            print(f\"\"\"Found Character: {word}\"\"\")\n",
    "    i+=1\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Character in (1): Stone Harry\n",
      "Found Character in (1): Harry Potter\n",
      "Found Character in (4): Mrs Dursley\n",
      "Found Character in (5): Mr Dursley\n",
      "Found Character in (5): Mrs Dursley\n",
      "Found Character in (5): Dudley\n",
      "Found Character in (6): Mrs Potter\n",
      "Found Character in (6): Mrs Dursley\n",
      "Found Character in (6): Dudley\n",
      "Found Character in (7): Mrs Dursley\n",
      "Found Character in (7): Mr Dursley\n",
      "Found Character in (7): Mrs Dursley\n",
      "Found Character in (7): Dudley\n",
      "Found Character in (9): Mr Dursley\n",
      "Found Character in (9): Mrs Dursley\n",
      "Found Character in (9): Dudley\n",
      "Found Character in (9): Dudley\n",
      "Found Character in (9): Mr Dursley\n",
      "Found Character in (10): Mr Dursley\n",
      "Found Character in (10): Mr Dursley\n",
      "Found Character in (10): Mr Dursley\n",
      "Found Character in (10): Mr Dursley\n",
      "Found Character in (11): Mr Dursley\n",
      "Found Character in (11): Mr Dursley\n",
      "Found Character in (11): Mr Dursley\n",
      "Found Character in (11): Mr Dursley\n",
      "Found Character in (12): Mr Dursley\n",
      "Found Character in (12): Mr Dursley\n",
      "Found Character in (14): I\n",
      "Found Character in (14): Harry\n",
      "Found Character in (15): Mr Dursley\n",
      "Found Character in (16): Potter\n",
      "Found Character in (16): Potter\n",
      "Found Character in (16): Harry\n",
      "Found Character in (16): Harry\n",
      "Found Character in (16): Mrs Dursley\n",
      "Found Character in (18): Mr Dursley\n",
      "Found Character in (19): Mr Dursley\n",
      "Found Character in (20): Mr Dursley\n",
      "Found Character in (22): Mr Dursley\n",
      "Found Character in (22): Mr Dursley\n",
      "Found Character in (23): Mrs Dursley\n",
      "Found Character in (23): Dudley\n",
      "Found Character in (23): Mr Dursley\n",
      "Found Character in (23): When Dudley\n",
      "Found Character in (25): Well Ted\n",
      "Found Character in (25): I\n",
      "Found Character in (25): I\n",
      "Found Character in (25): But I\n",
      "Found Character in (26): Mr Dursley\n",
      "Found Character in (27): Mrs Dursley\n",
      "Found Character in (28): Mrs Dursley\n",
      "Found Character in (30): Mr Dursley\n"
     ]
    }
   ],
   "source": [
    "text_i = 1\n",
    "for text in hp.split('\\n\\n')[:30]:\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    text = re.sub('[^\\w ]+','', text)\n",
    "    words = text.split(' ')\n",
    "\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            if word in character_names and word not in stopwords:\n",
    "                if words[i-1][0].isupper():\n",
    "                    print(f\"\"\"Found Character in ({text_i}): {words[i-1]} {word}\"\"\")\n",
    "                else:\n",
    "                    print(f\"\"\"Found Character in ({text_i}): {word}\"\"\")\n",
    "        except IndexError:\n",
    "            pass\n",
    "        i+=1\n",
    "    text_i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Introduction to Machine Learning NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = hp.split('\\n\\n')[4]\n",
    "text = text.replace(\"\\n\", \" \").strip()\n",
    "#text = re.sub('[^\\w ]+','', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spacy.load(\"en_core_web_lg\") # large\n",
    "# spacy.load(\"en_core_web_sm\") # small\n",
    "\n",
    "#install\n",
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dursley PERSON\n",
      "Grunnings ORG\n",
      "Dursley PERSON\n",
      "Dursleys PERSON\n",
      "Dudley PERSON\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grunnings ORG\n",
      "Dursley PERSON\n",
      "Dursleys PERSON\n",
      "Dudley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text.replace('Mr. Dursley', 'Olympe Maxime'))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini ORG\n",
      "Grunnings ORG\n",
      "Dursley PERSON\n",
      "Dursleys PERSON\n",
      "Dudley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text.replace('Mr. Dursley', 'Nagini'))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dursley PERSON\n",
      "Grunnings ORG\n",
      "Dursley PERSON\n",
      "Dursleys PERSON\n",
      "Dudley PERSON\n",
      "Today DATE\n",
      "Two CARDINAL\n",
      "1 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text + \" Today is Tuesday the 18th. Two is larger than 1.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dursley PERSON\n",
      "Grunnings ORG\n",
      "Dursley PERSON\n",
      "Dursleys PERSON\n",
      "Dudley PERSON\n",
      "Two CARDINAL\n",
      "1 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text + \" Today is November the 18th. Two is larger than 1.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2400/0*K5a1Ws_nsbEjhbYk.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what does spacy?\n",
    "Image(url= \"https://miro.medium.com/max/2400/0*K5a1Ws_nsbEjhbYk.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 using spaCy's Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ron Weasley', 'Hermione Granger', 'Lord Voldemort',\n",
       "       'Severus Snape', 'Rubeus Hagrid', 'Draco Malfoy', 'Ginny Weasley',\n",
       "       'Luna Lovegood', 'Neville Longbottom', 'Minerva McGonagall'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    odor'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"\"\"[Tt]he|[Aa]nd\"\"\", \"\", \"\"\"The the and And Theodor\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Theodor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"\"\"[Tt]he |[Aa]nd\"\"\", \"\", \"\"\"The the and And Theodor\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ron Weasley',\n",
       " 'Hermione Granger',\n",
       " 'Lord Voldemort',\n",
       " 'Severus Snape',\n",
       " 'Rubeus Hagrid',\n",
       " 'Draco Malfoy',\n",
       " 'Ginny Weasley',\n",
       " 'Luna Lovegood',\n",
       " 'Neville Longbottom',\n",
       " 'Minerva McGonagall']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_characters=[]\n",
    "for char in characters:\n",
    "    char = re.sub(\"\"\"[Tt]he|\"\"\", \"\", char)\n",
    "    char = re.sub(\"\"\"\\s+\"\"\", \" \", char)\n",
    "    new_characters.append(char)\n",
    "\n",
    "new_characters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ron Weasley',\n",
       " 'Ron',\n",
       " 'Weasley',\n",
       " 'Dr. Weasley',\n",
       " 'Professor Weasley',\n",
       " 'Mr. Weasley',\n",
       " 'Mrs. Weasley',\n",
       " 'Ms. Weasley',\n",
       " 'Miss Weasley',\n",
       " 'Aunt Weasley']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [\"Dr.\", \"Professor\", \"Mr.\",\"Mrs.\", \"Ms.\", \"Miss\", \"Aunt\", \"Uncle\", \"Mr. and Mrs.\"]\n",
    "\n",
    "final_characters = []\n",
    "for char in new_characters:\n",
    "    final_characters.append(char.strip())\n",
    "    final_characters.append(char.split()[0].strip())\n",
    "    final_characters.append(char.split()[-1].strip())\n",
    "    for title in titles:\n",
    "        titled_char = f\"{title} {char.split()[-1]}\"\n",
    "        if titled_char not in char:\n",
    "            final_characters.append(titled_char.strip())\n",
    "            \n",
    "final_characters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'PERSON', 'pattern': 'Abbott'}, {'label': 'PERSON', 'pattern': 'Aberforth'}, {'label': 'PERSON', 'pattern': 'Aberforth Dumbledore'}, {'label': 'PERSON', 'pattern': 'Abraxas'}, {'label': 'PERSON', 'pattern': 'Abraxas Malfoy'}, {'label': 'PERSON', 'pattern': 'Alastor'}, {'label': 'PERSON', 'pattern': 'Alastor Moody'}, {'label': 'PERSON', 'pattern': 'Albert'}, {'label': 'PERSON', 'pattern': 'Albert Runcorn'}, {'label': 'PERSON', 'pattern': 'Albus'}]\n"
     ]
    }
   ],
   "source": [
    "def creat_training_data(data, data_type):\n",
    "    patterns = []\n",
    "    \n",
    "    for item in data:\n",
    "        pattern = {\n",
    "            \"label\": data_type,\n",
    "            \"pattern\": item           \n",
    "        }\n",
    "        patterns.append(pattern)\n",
    "    return patterns\n",
    "        \n",
    "patterns = creat_training_data(data=sorted(final_characters), data_type=\"PERSON\")\n",
    "\n",
    "print(patterns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules(patterns):\n",
    "    nlp = English()\n",
    "    ruler = EntityRuler(nlp)\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "    nlp.to_disk('hp_ner')\n",
    "    \n",
    "generate_rules(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('hp_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley PERSON\n",
      "Mrs. Dursley PERSON\n",
      "Dudley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini PERSON\n",
      "Mrs. Dursley PERSON\n",
      "Dudley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text.replace('Mr. Dursley', 'Nagini'))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Training a spaCy NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA[(text, {\"entities\":[(start_entity, end_entity, label)]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini 0 6 PERSON\n",
      "Mrs. Dursley 161 173 PERSON\n",
      "Dudley 389 395 PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = hp.split('\\n\\n')[3]\n",
    "text = text.replace(\"\\n\", \" \").strip()\n",
    "#text = re.sub('[^\\w ]+','', text)\n",
    "\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3032/3032 [00:00<00:00, 3037.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"Harry Potter and the Sorcerer's Stone\", {'entities': [(0, 12, 'PERSON')]}], [\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\", {'entities': [(0, 20, 'PERSON')]}], ['Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.', {'entities': [(0, 11, 'PERSON'), (166, 178, 'PERSON'), (394, 400, 'PERSON')]}], [\"The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, but they hadn't met for several years; in fact, Mrs. Dursley pretended she didn't have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn't want Dudley mixing with a child like that.\", {'entities': [(206, 217, 'PERSON'), (222, 234, 'PERSON'), (293, 305, 'PERSON'), (711, 717, 'PERSON')]}], ['When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.', {'entities': [(5, 25, 'PERSON'), (217, 228, 'PERSON'), (287, 299, 'PERSON'), (350, 356, 'PERSON')]}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for text in tqdm(hp.split('\\n\\n')):\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    \n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities.append( (ent.start_char, ent.end_char, ent.label_) )\n",
    "\n",
    "    if len(entities)>0:\n",
    "        result = [text, {\"entities\": entities}]\n",
    "        train_data.append(result)        \n",
    "\n",
    "print(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckoss/miniconda3/envs/abd_workshop_2021/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "/home/ckoss/miniconda3/envs/abd_workshop_2021/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W034] Please install the package spacy-lookups-data in order to include the default lexeme normalization table for the language 'en'.\n",
      "  proc.begin_training(\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [01:57<56:54, 117.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 1190.1212724667828}\n",
      "Starting iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [04:08<58:39, 125.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 257.4625758977645}\n",
      "Starting iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [06:19<57:38, 128.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 179.01278866814081}\n",
      "Starting iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [08:30<55:57, 129.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 127.28947739240309}\n",
      "Starting iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [10:41<54:07, 129.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 116.12218869039317}\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [12:53<52:14, 130.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 94.42329238422118}\n",
      "Starting iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [15:05<50:12, 130.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 107.01615194412345}\n",
      "Starting iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [17:17<48:08, 131.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 112.49989755267833}\n",
      "Starting iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [19:30<46:05, 131.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 58.84788216660837}\n",
      "Starting iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [21:46<44:24, 133.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 73.65939048508356}\n",
      "Starting iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [25:00<48:04, 151.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 103.4645736179386}\n",
      "Starting iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [28:09<48:56, 163.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 62.571016549120245}\n",
      "Starting iteration 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [31:15<48:07, 169.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 81.914285995891}\n",
      "Starting iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [34:15<46:09, 173.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 72.33918153999785}\n",
      "Starting iteration 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [36:50<41:51, 167.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 78.40935126072387}\n",
      "Starting iteration 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [39:31<38:38, 165.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 78.64013137795072}\n",
      "Starting iteration 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [42:05<35:09, 162.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 100.8149738604597}\n",
      "Starting iteration 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [44:52<32:41, 163.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 37.07076607113968}\n",
      "Starting iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [48:08<31:45, 173.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 77.01631055070682}\n",
      "Starting iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [51:26<30:06, 180.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 46.55958342258336}\n",
      "Starting iteration 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [55:33<30:06, 200.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 94.88697055921342}\n",
      "Starting iteration 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [59:04<27:10, 203.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 57.82613893190236}\n",
      "Starting iteration 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [1:03:11<25:17, 216.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 60.673335081962755}\n",
      "Starting iteration 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [1:06:58<21:58, 219.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 82.14718610364297}\n",
      "Starting iteration 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [1:10:43<18:26, 221.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 72.62374652254414}\n",
      "Starting iteration 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [1:14:10<14:28, 217.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 56.91785386652102}\n",
      "Starting iteration 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [1:17:49<10:52, 217.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 61.37368787159892}\n",
      "Starting iteration 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [1:21:27<07:15, 217.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 43.98806502874159}\n",
      "Starting iteration 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [1:25:01<03:36, 216.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 60.148592117800035}\n",
      "Starting iteration 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:28:43<00:00, 177.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 50.196763980995975}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nStarting iteration 0\\n{'ner': 964.6060144836445}\\nStarting iteration 1\\n{'ner': 470.0375200238501}\\nStarting iteration 2\\n{'ner': 276.42840668701115}\\nStarting iteration 3\\n\\n\\n....\\n\\n\\nStarting iteration 27\\n{'ner': 56.020043512604765}\\nStarting iteration 28\\n{'ner': 52.933951228180256}\\nStarting iteration 29\\n{'ner': 40.17626116715598}\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def train_spacy(data, iterations):\n",
    "    train_data = data\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        \n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "            \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in tqdm(range(iterations)):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            for text, annotations in train_data:\n",
    "                nlp.update(\n",
    "                    [text],\n",
    "                    [annotations],\n",
    "                    drop = 0.2,\n",
    "                    sgd = optimizer,\n",
    "                    losses = losses\n",
    "                )\n",
    "            print(losses)\n",
    "    return nlp\n",
    "\n",
    "#nlp= train_spacy(data = train_data, iterations = 30)\n",
    "#nlp.to_disk(\"hp_ner_model\")\n",
    "\n",
    "\"\"\"\n",
    "Starting iteration 0\n",
    "{'ner': 964.6060144836445}\n",
    "Starting iteration 1\n",
    "{'ner': 470.0375200238501}\n",
    "Starting iteration 2\n",
    "{'ner': 276.42840668701115}\n",
    "Starting iteration 3\n",
    "\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "Starting iteration 27\n",
    "{'ner': 56.020043512604765}\n",
    "Starting iteration 28\n",
    "{'ner': 52.933951228180256}\n",
    "Starting iteration 29\n",
    "{'ner': 40.17626116715598}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('hp_ner')\n",
    "doc = nlp(\"\"\"Gollum was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Mr. Dursley was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for char in final_characters if \"Gollum\" in final_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Gollum\" in hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gollum PERSON\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"hp_ner_model\")\n",
    "doc = nlp(\"\"\"Gollum was the director of a firm called Grunnings, which made drills\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Max was the director of a firm called Grunnings, which made drills\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Mr. Dursley was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Somerandomname was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry James PERSON\n",
      "Potter PERSON\n",
      "James PERSON\n",
      "Lily Potter PERSON\n",
      "Harry PERSON\n",
      "Neville Longbottom PERSON\n",
      "Lord Voldemort PERSON\n",
      "Voldemort PERSON\n",
      "Severus Snape PERSON\n",
      "Harry PERSON\n",
      "Lord PERSON\n",
      "Potter PERSON\n",
      "Voldemort PERSON\n",
      "Harry PERSON\n",
      "Harry PERSON\n",
      "Harry PERSON\n",
      "Voldemort PERSON\n",
      "First PERSON\n",
      "Harry PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"\n",
    "Harry James Potter was an English half-blood wizard, and one of the most famous wizards of modern times. The only child and son of James and Lily Potter (née Evans), Harry's birth was overshadowed by a prophecy, naming either himself or Neville Longbottom as the one with the power to vanquish Lord Voldemort. After half of the prophecy was reported to Voldemort, courtesy of Severus Snape, Harry was chosen as the target due to his many similarities with the Dark Lord. In turn, this caused the Potter family to go into hiding. Voldemort made his first vain attempt to circumvent the prophecy when Harry was a year and three months old. During this attempt, he murdered Harry's parents as they tried to protect him, but this unsuccessful attempt to kill Harry led to Voldemort's first downfall. This downfall marked the end of the First Wizarding War, and to Harry henceforth being known as \"The Boy Who Lived\", as he was the only known survivor of the Killing Curse.\n",
    "\"\"\".strip() )\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Introduction to Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HARRY', 'Harry', 'harry', 'POTTER', 'Potter', 'potter', 'Hermione', 'HERMIONE', 'hermione', 'Hallows']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def spacy_similarity(word):\n",
    "    ms = nlp.vocab.vectors.most_similar(\n",
    "        np.asarray([nlp.vocab.vectors[nlp.vocab.strings[word]]]), n=10)\n",
    "    words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    distances = ms[2]\n",
    "    print(words)\n",
    "    \n",
    "spacy_similarity(\"Harry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gollum', 'Gollum', 'GOLLUM', 'Gandalf', 'GANDALF', 'gandalf', 'frodo', 'FRODO', 'Frodo', 'smeagol']\n"
     ]
    }
   ],
   "source": [
    "spacy_similarity(\"Gollum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 Generating Custom Word Vectors in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone. CHAPTER ONE. THE BOY WHO LIVED. Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('''http://www.pauladaunt.com/books/Children's/Harry_Potter1-4/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt''')\n",
    "hp = r.content.decode('utf-8')\n",
    "hp = hp.replace('\\n\\n','. ').replace('..','.').replace('\\n',' ')\n",
    "hp = re.sub('\\s+',' ', hp)\n",
    "\n",
    "print(hp[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Harry', 'Potter', 'Sorcerers', 'Stone'],\n",
       " ['CHAPTER', 'ONE'],\n",
       " ['THE', 'BOY', 'WHO', 'LIVED'],\n",
       " ['Mr',\n",
       "  'Mrs',\n",
       "  'Dursley',\n",
       "  'number',\n",
       "  'Privet',\n",
       "  'Drive',\n",
       "  'proud',\n",
       "  'perfectly',\n",
       "  'normal',\n",
       "  'thank'],\n",
       " ['They',\n",
       "  'people',\n",
       "  'youd',\n",
       "  'expect',\n",
       "  'involved',\n",
       "  'strange',\n",
       "  'mysterious',\n",
       "  'didnt',\n",
       "  'hold',\n",
       "  'nonsense']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "def cleaning(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(\"[^\\w ]\",\"\", text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in nlp.Defaults.stop_words]\n",
    "    return text\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer')) \n",
    "doc = nlp(hp)\n",
    "hp = [tokenize(cleaning(sent)) for sent in doc.sents]\n",
    "hp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = hp\n",
    "def training(model_name):\n",
    "    sentences = hp\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(\n",
    "        min_count = 5, # min freq of word\n",
    "        window = 2, # surrounding words of w2v\n",
    "        vector_size = 500 , # dimensionality of a token\n",
    "        sample = 6e-5,\n",
    "        alpha = 0.03,\n",
    "        min_alpha = 0.0007,\n",
    "        negative = 20,\n",
    "        workers = cores-1\n",
    "    )\n",
    "      \n",
    "    w2v_model.build_vocab(sentences)\n",
    "    w2v_model.train(sentences, total_examples = w2v_model.corpus_count, epochs=30)\n",
    "    w2v_model.save(f\"\"\"word_vectors/{model_name}.model\"\"\")\n",
    "    w2v_model.wv.save_word2vec_format(f\"\"\"word_vectors/word2vec_{model_name}.txt\"\"\")\n",
    "    \n",
    "training(\"hp_ner_model_01\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_similarity(word):\n",
    "    model = KeyedVectors.load_word2vec_format(\"word_vectors/word2vec_hp_ner_model_01.txt\", binary=False)\n",
    "    results = model.most_similar(positive=[word])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shouted', 0.999816358089447), ('noticed', 0.9998037219047546), ('sir', 0.9997997283935547), ('For', 0.9997996091842651), ('knocked', 0.9997986555099487), ('train', 0.9997981190681458), ('Griphook', 0.9997978210449219), ('Even', 0.9997971653938293), ('kicked', 0.9997969269752502), ('sharply', 0.9997965693473816)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity(\"Harry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('points', 0.9997794032096863), ('If', 0.9997761845588684), ('Slytherin', 0.9997742176055908), ('taken', 0.9997738003730774), ('Theres', 0.9997723698616028), ('So', 0.9997720122337341), ('Hell', 0.9997705221176147), ('Its', 0.9997681975364685), ('Gryffindors', 0.9997647404670715), ('Five', 0.9997645616531372)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity(\"Gryffindor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 Importing Custom Word Vectors from Gensim into spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "word_vectors = \"word_vectors/word3vechp_ner_model_01.txt\"\n",
    "model_name = \"hp_model_test\"\n",
    "\n",
    "def load_word_vectors(model_name, word_vectors):\n",
    "    subprocess.run([sys.executable,\n",
    "                   \"-m\",\n",
    "                    \"spacy\",\n",
    "                   \"init-model\",\n",
    "                   \"en\",\n",
    "                   model_name,\n",
    "                   \"--vectors-loc\",\n",
    "                   word_vectors]\n",
    "    )\n",
    "load_word_vectors(model_name, word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:abd_workshop_2021] *",
   "language": "python",
   "name": "conda-env-abd_workshop_2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
