{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Introduction to NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/602/1*bx85lgIdG9PWdCCnfNpsjQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Key Terminology:\n",
    "\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    Named Entity Recognition (NER)\n",
    "    \n",
    "    Information Extraction (IE)\n",
    "    \n",
    "    Gazetteer (Rules-Based Method)\n",
    "    \n",
    "    Linguistic Ambiguity\n",
    "    \n",
    "    Domain Adaptation\n",
    "    \n",
    "    Generalize\n",
    "\n",
    "\n",
    "\n",
    "Key Libraries:\n",
    "\n",
    "    NLP           ==> spaCy & NLTK\n",
    "    \n",
    "    Word Vectors  ==> Gensim\n",
    "\"\"\"\n",
    "\n",
    "# images\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/602/1*bx85lgIdG9PWdCCnfNpsjQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is an entity?\n",
    "\n",
    "An entity is a \"Thing\" existing in the real world or in our imagination.\n",
    "\n",
    "Words are a way to describe a \"Thing\", but aren't the \"Thing\" itself.\n",
    "\n",
    "Instead of always describing something, we nearly have a name for everything:\n",
    "\n",
    "e.g.: Lord Voldemort\n",
    "- He Who Must Not Be Named\n",
    "- You-Know-Who\n",
    "- Voldemort\n",
    "- You Know Who\n",
    "- Dark Lord Voldemort\n",
    "- Dark Lord\n",
    "- Tom Riddle\n",
    "- Tom Marvolo Riddle\n",
    "- He-Who-Must-Not-Be-Named\n",
    "\n",
    "\n",
    "Even when we forget the name of an entity, language enables us to describe the entity so, that other know what we mean:\n",
    "\n",
    "e.g.: Lord Voldemort\n",
    "- a fictional character and the main antagonist in J. K. Rowling's series of Harry Potter novels\n",
    "- that evil wizard from Harry Potter missing a nose\n",
    "\n",
    "\n",
    "https://www.wikidata.org/wiki/Q176132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    University Bremen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Universität Bremen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">University \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Stuttgart\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Universität Stuttgart\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">University \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wuppertal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Universität Wuppertal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "# https://spacy.io/models/en#en_core_web_lg\n",
    "# needs to be extra installed 700MB+ \n",
    "#!python3 -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# The issues with entity recognition of general models\n",
    "show_doc = \"University Bremen\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Universität Bremen\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"University Stuttgart\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Universität Stuttgart\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"University Wuppertal\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Universität Wuppertal\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harry Potter domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dursley\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dursley\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Durley\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Durley\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Randomname\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Lord \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Randomname\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the uncle of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc = \"Dursley is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Mr. Dursley is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Durley is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Mr. Durley is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Mr. Randomname is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Lord Randomname is the uncle of Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Lord \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Voldemort\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the evil character in \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"189479664b2b4af3abd0fdc6859956ff-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Lord</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Voldemort</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">evil</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">character</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Harry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Potter.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-189479664b2b4af3abd0fdc6859956ff-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-189479664b2b4af3abd0fdc6859956ff-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc = \"Lord Voldemort is the evil character in Harry Potter.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "spacy.displacy.render(nlp(show_doc), style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Voldemort\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the evil character in the book \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and the Sorcerer's Stone.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc = \"Voldemort is the evil character in the book Harry Potter and the Sorcerer's Stone.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Voldemort\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is my dog.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Voldemort\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a company.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc = \"Voldemort is my dog.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")\n",
    "\n",
    "show_doc = \"Voldemort is a company.\"\n",
    "spacy.displacy.render(nlp(show_doc), style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Get data and do some preprocessing\n",
    "\n",
    "This Chapter contains:\n",
    "- preprocessing Text\n",
    "- loading Text into spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  439742\n",
      "\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "nearly \n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "\n",
    "# get the first Harry Potter Book\n",
    "r = requests.get('''http://www.pauladaunt.com/books/Children's/Harry_Potter1-4/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt''')\n",
    "hp = r.content.decode('utf-8')\n",
    "print('length: ',len(hp))\n",
    "print('\\n')\n",
    "print(hp[:550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone. CHAPTER ONE. THE BOY WHO LIVED. Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly tw\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate linebreak, multiple spaces and multiple dots and similar patterns\n",
    "hp_flat = re.sub('\\s+', ' ', hp.replace('\\n\\n','. ').replace('\\n',' ').strip())\n",
    "hp_flat = re.sub('[.]+', '.', hp_flat)\n",
    "hp_flat = hp_flat.replace(':.','.').replace(';.','.').replace(',.','.')\n",
    "hp_flat[:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters used in corpus:  !\"'()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\abcdefghijklmnopqrstuvwxyz~\n",
      "Symbols: \"'()*-:;\\~\n",
      "\n",
      "\n",
      "{\"'\": 3141, ';': 129, '-': 1990, '\"': 4758, '(': 30, ')': 33, ':': 48, '~': 1, '*': 2, '\\\\': 1}\n"
     ]
    }
   ],
   "source": [
    "# check characters\n",
    "chars = ''.join(sorted(set(hp.replace('\\n','').replace('\\t',''))))\n",
    "print('Characters used in corpus:',chars)\n",
    "\n",
    "# filter for symbols\n",
    "symbols = re.sub('[A-Za-z0-9!?., ]','', chars)\n",
    "print('Symbols:',symbols)\n",
    "\n",
    "# get frequency of each symbol\n",
    "from collections import Counter\n",
    "print('\\n')\n",
    "print({k:v for k,v in Counter(hp_flat).items() if k in symbols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\": g a tantrum and throwing his cereal at the walls. \"Little tyke,\" chortled Mr. Dursley as he left the\n",
      "': Harry Potter and the Sorcerer's Stone. CHAPTER ONE. THE BOY WHO LIVED. Mr. and \n",
      "(: er daughter and how Dudley had learned a new word (\"Won't!\"). Mr. Dursley tried to act normally. Whe\n",
      "): er and how Dudley had learned a new word (\"Won't!\"). Mr. Dursley tried to act normally. When Dudley \n",
      "*: ue, but Ron kicked him behind their cauldron. \"Doi* push it,\" he muttered, \"I've heard Snape can tur\n",
      "-: n't have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it wa\n",
      "::  to persuade people to call him by his proper name: Voldemort.\" Professor McGonagall flinched, but D\n",
      ";: ey's sister, but they hadn't met for several years; in fact, Mrs. Dursley pretended she didn't have \n",
      "\\: to save me?\". \"Of course,\" said Quirrell coolly. \"\\Why do you think he wanted to referee your next m\n",
      "~: er ours. Some of 'em came outta kinda trances. Don~ reckon they could've done if he was comin' back.\n"
     ]
    }
   ],
   "source": [
    "# check usage of symbols in text\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "for symbol in symbols:\n",
    "    symbol_position = find_nth(hp_flat, symbol, 1)\n",
    "    print(f\"\"\"{symbol}: {hp_flat[max(0,symbol_position-50):symbol_position+50]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(\"Won\\'t!\")',\n",
       " \"(he'd be able to watch what he wanted on television for a change and maybe even have a go on Dudley's computer)\",\n",
       " '(brown with orange puff balls)',\n",
       " '(as he shouted at Uncle Vernon through the locked door of his cupboard)',\n",
       " '(or maybe hoped)',\n",
       " \"(usually Uncle Vernon's sister, Marge)\",\n",
       " '(two minutes to go)',\n",
       " '(Order of Merlin, First Class, Grand Sorc., Chf. Warlock, Supreme Mugwump, International Confed. of Wizards)',\n",
       " '(black)',\n",
       " '(black)',\n",
       " '(dragon hide or similar)',\n",
       " '(black, silver fastenings)',\n",
       " '(Grade 1)',\n",
       " '(pewter, standard size 2)',\n",
       " '(chocolate and raspberry with chopped nuts)',\n",
       " '(Bewitch Your Friends and Befuddle Your Enemies with the Latest Revenges: Hair Loss, Jelly-Legs, Tongue- Tying and Much, Much More)',\n",
       " '(\"It says pewter on yer list\")',\n",
       " '(five Knuts a scoop)',\n",
       " '(feeling foolish)',\n",
       " '(the sandwiches lay forgotten)',\n",
       " '(though I have none)',\n",
       " '(\"I do hope they start right away, there\\'s so much to learn, I\\'m particularly interested in Transfiguration, you know, turning something into something else, of course, it\\'s supposed to be very difficult-\"; \"You\\'ll be starting small, just matches into needles and that sort of thing -- \")',\n",
       " '(except perhaps the Weasley twins)',\n",
       " \"(Neville wasn't back from the hospital wing)\",\n",
       " '(which was a relief, because Neville had been trying to catch his eye)',\n",
       " '(\"How will you learn?\")',\n",
       " '(Slytherin would be playing in green)',\n",
       " '(\"If Filch had caught you!\")',\n",
       " '(six hundred and fifty-eight)',\n",
       " '(\"I always hope they\\'ll forget to give us these,\" said Fred Weasley sadly)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check bracket contents\n",
    "re.findall(\"\"\"\\([^()]+\\)\"\"\", hp_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary symbols\n",
    "hp_flat = re.sub(\"[*~]\", \"\", hp_flat).replace(\"\\\\\", \"\")\n",
    "\n",
    "# delete brackets and content, if they don't seem to be important\n",
    "hp_flat = re.sub(\"\"\"\\([^()]+\\)\"\"\", \"\",hp_flat).replace('(','').replace(')','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text should be ready to be feeded into the spacy pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Harry Potter and the Sorcerer's Stone.,\n",
       " CHAPTER ONE.,\n",
       " THE BOY WHO LIVED.,\n",
       " Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.,\n",
       " They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.,\n",
       " Mr. Dursley was the director of a firm called Grunnings, which made drills.,\n",
       " He was a big, beefy man with hardly any neck, although he did have a very large mustache.,\n",
       " Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.,\n",
       " The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.,\n",
       " The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it.]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# nlp is a natural language processing function of spacy, that includes many useful functions\n",
    "doc = nlp(hp_flat)\n",
    "\n",
    "# transform the doc into a callable list of sentences for easier usage\n",
    "hp_sentences = []\n",
    "for sentence in doc.sents:\n",
    "    #filter empty sentences\n",
    "    if sentence.text.strip():\n",
    "        hp_sentences.append(sentence)\n",
    "hp_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Explore some spacy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this chapter contains:\n",
    "- exploring parts of spacy\n",
    "- first check for entities\n",
    "- the issue of general models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone.\n",
      "Harry Potter PERSON\n",
      "\n",
      "\n",
      "CHAPTER ONE.\n",
      "ONE CARDINAL\n",
      "\n",
      "\n",
      "THE BOY WHO LIVED.\n",
      "\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\n",
      "Dursley PERSON\n",
      "four CARDINAL\n",
      "Privet Drive FAC\n",
      "\n",
      "\n",
      "They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
      "\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills.\n",
      "Dursley PERSON\n",
      "Grunnings ORG\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/usage/linguistic-features\n",
    "\n",
    "# let's see if we can identify some entities using spacy\n",
    "for sentence in hp_sentences[:6]:\n",
    "    print('\\n')\n",
    "    print(sentence)\n",
    "    for ent in sentence.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "        \n",
    "# Not bad! Spacy got some good hits there! But does spacy really recognize those entities or was it just luck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can actually checkout what spacy connects with a single word\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# A functions that calls word-vectors from spacy, containing words, that are associated with the input word\n",
    "def spacy_similarity(word):\n",
    "    ms = nlp.vocab.vectors.most_similar(\n",
    "        np.asarray([nlp.vocab.vectors[nlp.vocab.strings[word]]]), n=10)\n",
    "    words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    distances = ms[2]\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HARRY', 'Harry', 'harry', 'POTTER', 'Potter', 'potter', 'Hermione', 'HERMIONE', 'hermione', 'Hallows']\n",
      "None\n",
      "['POTTER', 'Potter', 'potter', 'HARRY', 'harry', 'Harry', 'Hallows', 'hallows', 'deathly', 'Deathly']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Seems like Spacy knows some Harry Potter stuff\n",
    "print(spacy_similarity(\"Harry\"))\n",
    "print(spacy_similarity(\"Potter\"))\n",
    "\n",
    "# As we can see <Potter> is in the top 5 in the <Harry>-Vector\n",
    "# Also <Harry> is in the top 5 in the <Potter>-Vector\n",
    "# No surprise, spacy nailed that one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for <Dursely>:\n",
      "['Dursley', 'dursley', 'wallasey', 'prescot', 'whitchurch', 'petersfield', 'clitheroe', 'Westhill', 'westhill', 'consett']\n",
      "\n",
      "\n",
      "Mr. Dursley is a person. # Dursley PERSON\n",
      "Dursley is a person. # Dursley GPE\n",
      "Dursley from Harry Potter. # Dursley GPE\n",
      "Dursley from Harry Potter. # Harry Potter PERSON\n",
      "Dursley # Dursley GPE\n"
     ]
    }
   ],
   "source": [
    "# Spacy mainly associates locations with <Dursley>, but still detected <Dursley> as a Person. Good job spacy! \n",
    "print(\"Vector for <Dursely>:\")\n",
    "spacy_similarity(\"Dursley\")\n",
    "print('\\n')\n",
    "\n",
    "# Spacy does this by recognizing patterns. The striking pattern for spacy was <Mr.> <Noun>.\n",
    "temp = nlp('Mr. Dursley is a person.')\n",
    "for ent in temp.ents:\n",
    "    print('Mr. Dursley is a person. #',ent.text, ent.label_)\n",
    "    \n",
    "# If we remove the <Mr.> pattern, spacy fails to detect <Dursley> as a person, although we made it obvious.\n",
    "temp = nlp('Dursley is a person.')\n",
    "for ent in temp.ents:\n",
    "    print('Dursley is a person. #', ent.text, ent.label_)\n",
    "    \n",
    "# Obviously Spacy doesn't know anything about Mr. Dursley from Harry Potter.\n",
    "temp = nlp('Dursley from Harry Potter.')\n",
    "for ent in temp.ents:\n",
    "    print('Dursley from Harry Potter. #', ent.text, ent.label_)\n",
    "    \n",
    "# If spacy doesn't detect any pattern, it simply falls back to the default tag.    \n",
    "temp = nlp('Dursley')\n",
    "for ent in temp.ents:\n",
    "    print('Dursley #', ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini not in data.\n"
     ]
    }
   ],
   "source": [
    "# Nagini is a talking snake and the pet of Voldemort, doesn't look like spacy knows Nagini, yet\n",
    "try:\n",
    "    spacy_similarity(\"Nagini\")\n",
    "except KeyError:\n",
    "    print(\"Nagini not in data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini is a person. # Nagini ORG\n"
     ]
    }
   ],
   "source": [
    "# Oh no, what is spacy doing here?\n",
    "temp = nlp('Nagini is a person.')\n",
    "for ent in temp.ents:\n",
    "    print('Nagini is a person. #',ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomname is a person. # Randomname ORG\n",
      "Harry is a person. # Harry PERSON\n",
      "Harry is a organization. # Harry PERSON\n"
     ]
    }
   ],
   "source": [
    "# Seems like the pattern <token> is a person, always makes spacy default to ORG ...\n",
    "temp = nlp('Randomname is a person.')\n",
    "for ent in temp.ents:\n",
    "    print('Randomname is a person. #',ent.text, ent.label_)\n",
    "    \n",
    "# ... unless we make it even obvious ...\n",
    "temp = nlp('Harry is a person.')\n",
    "for ent in temp.ents:\n",
    "    print('Harry is a person. #',ent.text, ent.label_)\n",
    "\n",
    "# ... or may be spacy doesn't really understand us?\n",
    "temp = nlp('Harry is a organization.')\n",
    "for ent in temp.ents:\n",
    "    print('Harry is a organization. #',ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Get Metadata about the domain of interest from Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter contains:\n",
    "- collecting metadata for entities from wikidata\n",
    "\n",
    "Recognizing entities in an unknown domain can be very difficult.\n",
    "\n",
    "Normally we would have to label entities manually, but with the help of the internet we may save some tedious work.\n",
    "\n",
    "One of the biggest sources for information are Knowledge Bases like wikidata.\n",
    "\n",
    "With some luck, we can even manage to find a whole group working on our specific domain: e.g.  https://www.wikidata.org/wiki/Wikidata:WikiProject_Harry_Potter\n",
    "\n",
    "Besides wikidata there are various other sources, which may need some more preprocessing, but still can be very helpful.\n",
    "\n",
    "Warning: You may always check the data you didn't created yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# We are using the Wikidata SPARQL API to easily receive Metadata of good quality\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "\n",
    "############################################\n",
    "# Creating a query for receiving data - Here the domain is the \"Harry Potter Universe\"\n",
    "\n",
    "# ?item wdt:P1441 wd:Q8337.               -> items that are <present in> (P1441) <Harry Potter Books> (Q8337)\n",
    "# ?item wdt:P31  wd:Q3658341.             -> items that are <instance of> (P31) <literaly character> (Q3658341)\n",
    "# SERVICE wikibase:label { bd:service ... -> Select in <english> (en)\n",
    "# Optional{?item skos:altLabel ?altLabel. -> <Optional> items that have <alternative labels>\n",
    "# FILTER (lang(?altLabel) = \"en\")}        -> Filter only alternative lables (?altLabel) by language english\n",
    "############################################\n",
    "query = \"\"\"\n",
    "            SELECT ?item ?itemLabel ?altLabel\n",
    "            WHERE \n",
    "            {\n",
    "              ?item wdt:P1441 wd:Q8337.\n",
    "              ?item wdt:P31 wd:Q3658341.\n",
    "              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\"}.\n",
    "              Optional{?item skos:altLabel ?altLabel . FILTER (lang(?altLabel) = \"en\")}\n",
    "            }\n",
    "\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the query looks like in the API:\n",
    "\n",
    "https://query.wikidata.org/#SELECT%20%3Fitem%20%3FitemLabel%20%3FaltLabel%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP1441%20wd%3AQ8337.%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ3658341.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22%7D.%0A%20%20Optional%7B%3Fitem%20skos%3AaltLabel%20%3FaltLabel%20.%20FILTER%20%28lang%28%3FaltLabel%29%20%3D%20%22en%22%29%7D%0A%7D%0A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>altLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Q1000118</td>\n",
       "      <td>Peter Pettigrew</td>\n",
       "      <td>Wormtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Q1000118</td>\n",
       "      <td>Peter Pettigrew</td>\n",
       "      <td>Scabbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q10264933</td>\n",
       "      <td>Demelza Robins</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Q10266348</td>\n",
       "      <td>Dilys Derwent</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Q10269234</td>\n",
       "      <td>Damocles Rowle</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Q9617281</td>\n",
       "      <td>Anthony Goldstein</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Q9631186</td>\n",
       "      <td>Artemisia Lufkin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Q9640654</td>\n",
       "      <td>Avery</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Q9659949</td>\n",
       "      <td>Bob Ogden</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Q9703083</td>\n",
       "      <td>Cassandra Trelawney</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          item            itemLabel  altLabel\n",
       "259   Q1000118      Peter Pettigrew  Wormtail\n",
       "258   Q1000118      Peter Pettigrew  Scabbers\n",
       "116  Q10264933       Demelza Robins          \n",
       "117  Q10266348        Dilys Derwent          \n",
       "118  Q10269234       Damocles Rowle          \n",
       "..         ...                  ...       ...\n",
       "111   Q9617281    Anthony Goldstein          \n",
       "112   Q9631186     Artemisia Lufkin          \n",
       "113   Q9640654                Avery          \n",
       "114   Q9659949            Bob Ogden          \n",
       "115   Q9703083  Cassandra Trelawney          \n",
       "\n",
       "[299 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to receive the data in json format\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "# Function to unpack the wanted values and remove empty results\n",
    "def try2unpack(x):\n",
    "    try:\n",
    "        x=x['value']\n",
    "    except (KeyError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if 'http://www.wikidata.org/entity/Q' in x or 'http://www.wikidata.org/entity/P' in x:\n",
    "            return x.rsplit('/',1)[1]\n",
    "        else:\n",
    "            return x\n",
    "    except TypeError:\n",
    "        return x\n",
    "    \n",
    "# Funtion to transform the data into a pandas DataFrame\n",
    "def json2pandas(data):\n",
    "    return pd.DataFrame(data['results']['bindings'], columns=data['head']['vars']).applymap(lambda x: try2unpack(x))\n",
    "\n",
    "\n",
    "# Execute\n",
    "results = get_results(endpoint_url, query)\n",
    "characters = json2pandas(results).fillna('')\n",
    "characters.sort_values('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spout-Hole', 'Q15257494'),\n",
       " ('Cedrella Weasley', 'Q15269290'),\n",
       " ('Callidora Longbottom', 'Q15269305'),\n",
       " ('Ursula Black', 'Q15269368'),\n",
       " ('Sirius Black', 'Q713701'),\n",
       " ('Melania Black', 'Q15272785'),\n",
       " ('Hesper Black', 'Q15272848'),\n",
       " ('Irma Black', 'Q15272917'),\n",
       " ('Ronald Bilius \"Ron\" Weasley', 'Q173998'),\n",
       " ('Ronald Bilius Weasley', 'Q173998')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to a dictionary, so that every word representation points on it's entity\n",
    "\n",
    "characters_dictionary = {}\n",
    "\n",
    "# 1) point alternative word representation to the entity\n",
    "for index, row in characters.iterrows():\n",
    "    if row['altLabel']:\n",
    "        characters_dictionary[ row['altLabel'] ]  = row['item']\n",
    "        \n",
    "# 2) point primary word representationto entity - By doing this 2) it may overwrite data from 1).\n",
    "for index, row in characters.iterrows():\n",
    "    if row['itemLabel']:\n",
    "        characters_dictionary[ row['itemLabel'] ] = row['item']\n",
    "\n",
    "list(characters_dictionary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Voldemort: Q176132\n",
      "Lord Voldemort: Q176132\n",
      "\n",
      "Tom Riddle: Q2182794\n"
     ]
    }
   ],
   "source": [
    "# 'Lord Voldemort' and 'You Know Who' refer now to the same identity: Q176132.\n",
    "print('Lord Voldemort:', characters_dictionary.get('Lord Voldemort'))\n",
    "print('Lord Voldemort:', characters_dictionary.get('You Know Who'))\n",
    "\n",
    "# Although Lord Voldemort is known as 'Tom Riddle', 'Tom Riddle' is also the father of Voldemort: Q2182794.\n",
    "print('\\nTom Riddle:', characters_dictionary.get('Tom Riddle'))\n",
    "\n",
    "# A word representation can point to two different entities.\n",
    "# To figure out which is the correct entity, we have to include the surrounding context of the word representation.\n",
    "# For now we leave 'Tom Riddle' as Q2182794, the father of Voldemort (Q176132)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally collected some clean representations for our entities. In the next step we need to identify the entities in the real text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Gazetteer and NER (Rules-Based NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter contains:\n",
    "- creating own entity labels for spacy, with very low effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>altLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Q5700415</td>\n",
       "      <td>Dudley Dursley</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Q11910388</td>\n",
       "      <td>Vernon Dursley</td>\n",
       "      <td>Mr. Dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Q11910388</td>\n",
       "      <td>Vernon Dursley</td>\n",
       "      <td>Uncle Vernon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Q1963397</td>\n",
       "      <td>Petunia Dursley</td>\n",
       "      <td>Aunt Petunia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Q1963397</td>\n",
       "      <td>Petunia Dursley</td>\n",
       "      <td>Mrs. Dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Q1963397</td>\n",
       "      <td>Petunia Dursley</td>\n",
       "      <td>Petunia Evans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item        itemLabel       altLabel\n",
       "89    Q5700415   Dudley Dursley               \n",
       "272  Q11910388   Vernon Dursley    Mr. Dursley\n",
       "273  Q11910388   Vernon Dursley   Uncle Vernon\n",
       "277   Q1963397  Petunia Dursley   Aunt Petunia\n",
       "278   Q1963397  Petunia Dursley   Mrs. Dursley\n",
       "279   Q1963397  Petunia Dursley  Petunia Evans"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if we can fix Dursley with some own easy methods\n",
    "\n",
    "# Let's see what wikidata entitiy we have for <Dursley>\n",
    "characters[characters['itemLabel'].str.contains('Dursley')]\n",
    "\n",
    "# We have 3 entities\n",
    "    # Dudley Dursley (son) #Q5700415\n",
    "    # Vernon Dursley (father) #Q11910388\n",
    "    # Petunia Dursley (mother) #Q1963397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aunt',\n",
       " 'Aunt Petunia',\n",
       " 'Dudley',\n",
       " 'Dudley Dursley',\n",
       " 'Dursley',\n",
       " 'Evans',\n",
       " 'Mr.',\n",
       " 'Mr. Dursley',\n",
       " 'Mrs.',\n",
       " 'Mrs. Dursley',\n",
       " 'Petunia',\n",
       " 'Petunia Dursley',\n",
       " 'Petunia Evans',\n",
       " 'Uncle',\n",
       " 'Uncle Vernon',\n",
       " 'Vernon',\n",
       " 'Vernon Dursley'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all entities for the Dursleys\n",
    "dursleys_entities = [v for k,v in characters_dictionary.items() if 'Dursley' in k]\n",
    "\n",
    "# get all variations for the Dursleys\n",
    "dursleys_variations = [[k for k,v in characters_dictionary.items() if entity==v] for entity in dursleys_entities]\n",
    "\n",
    "# flatten list\n",
    "dursleys_variations = [variation for entity_variations in dursleys_variations for variation in entity_variations]\n",
    "\n",
    "# add single names\n",
    "dursleys_variations = set(dursleys_variations + [name.split()[0] for name in dursleys_variations] + [name.split()[-1] for name in dursleys_variations])\n",
    "dursleys_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. and Mrs. Dursley visited their son Dudley.\n",
      "\n",
      "\n",
      "Mr.\n",
      "Mrs.\n",
      "Dursley\n",
      "Dudley\n"
     ]
    }
   ],
   "source": [
    "# finding entities via list\n",
    "\n",
    "sentence = nlp('Mr. and Mrs. Dursley visited their son Dudley.')\n",
    "\n",
    "print(sentence)\n",
    "print('\\n')\n",
    "for token in sentence:\n",
    "    if token.text in dursleys_variations:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley\n",
      "Mrs. Dursley\n",
      "Dudley\n"
     ]
    }
   ],
   "source": [
    "# create a more complex rule\n",
    "tokenized_sentence = [token.text for token in sentence]\n",
    "\n",
    "window = 3\n",
    "window_bigram = []\n",
    "token_already_used = []\n",
    "for i in range(len(tokenized_sentence)):\n",
    "    try:\n",
    "        actual_token = tokenized_sentence[i]\n",
    "        if actual_token in ['Mr.', 'Mrs.']:\n",
    "            for j in range(i+1, i+1+window):\n",
    "                next_token = tokenized_sentence[j]\n",
    "                window_bigram = actual_token+' '+next_token\n",
    "\n",
    "                if window_bigram in dursleys_variations:\n",
    "                    token_already_used.append(j)\n",
    "                    print(window_bigram)\n",
    "                    \n",
    "        else:\n",
    "            if actual_token in dursleys_variations and i not in token_already_used:\n",
    "                print(actual_token)\n",
    "            \n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Manipulate spaCy's Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter contains:\n",
    "- adding custom entities to spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'HP_CHAR', 'pattern': '\"BILL\"'}, {'label': 'HP_CHAR', 'pattern': '\"Bill\"'}, {'label': 'HP_CHAR', 'pattern': '\"RON\"'}, {'label': 'HP_CHAR', 'pattern': '\"ROSIE\"'}, {'label': 'HP_CHAR', 'pattern': '\"Ron\"'}, {'label': 'HP_CHAR', 'pattern': '\"Rosie\"'}, {'label': 'HP_CHAR', 'pattern': '\"TEDDY\"'}, {'label': 'HP_CHAR', 'pattern': '\"Teddy\"'}, {'label': 'HP_CHAR', 'pattern': \"'MAD-EYE'\"}, {'label': 'HP_CHAR', 'pattern': \"'Mad-Eye'\"}]\n"
     ]
    }
   ],
   "source": [
    "# create customized labels\n",
    "def creat_training_data(data, data_type):\n",
    "    patterns = []\n",
    "    \n",
    "    for item in data:\n",
    "        pattern = {\n",
    "            \"label\": data_type,\n",
    "            \"pattern\": item           \n",
    "        }\n",
    "        patterns.append(pattern)\n",
    "    return patterns\n",
    "        \n",
    "# prepare costumized entities, possibly you may modify or clean them\n",
    "characters = list(characters_dictionary.keys())    \n",
    "characters += ' '.join(characters).split()\n",
    "stoplist = ['the','and', 'i', 'he']\n",
    "characters = [character for character in characters if character.lower() not in stoplist]\n",
    "characters += [character.upper() for character in characters] + [character.title() for character in characters]\n",
    "\n",
    "# apply the new entities and save them as \"pattern\"\n",
    "patterns = creat_training_data(data=sorted(set(characters)), data_type=\"HP_CHAR\")\n",
    "\n",
    "print(patterns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new blank model and save the new \"patterns\" in it\n",
    "def generate_rules(patterns):\n",
    "    nlp = English()\n",
    "    ruler = EntityRuler(nlp)\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "    # the model will be saved as 'hp_ner', you may choose a different name\n",
    "    nlp.to_disk('hp_ner')\n",
    "    \n",
    "generate_rules(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Dudley HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "# we can load our customized patterns also from a file\n",
    "nlp = spacy.load('hp_ner')\n",
    "\n",
    "# a quick test shows, that our Model still labels text as expected\n",
    "sentence = 'Mr. and Mrs. Dursley visited their son Dudley.'\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagini HP_CHAR\n",
      "Dursley HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "# let's retry the former wrong labeled sentences\n",
    "\n",
    "doc = nlp('Nagini is a company')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "doc = nlp('Dursley is a company')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Training a spaCy NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter contains:\n",
    "- training a customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random will be used to shuffle the train data\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use customized entities to tag the data, we reparse every sentence with our new model using nlp()\n",
    "hp_sentences_new = [nlp(sentence.text) for sentence in hp_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7391/7391 [00:00<00:00, 53503.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Harry Potter and the Sorcerer's Stone.\",\n",
       "  {'entities': [(0, 12, 'HP_CHAR')]}],\n",
       " ['THE BOY WHO LIVED.', {'entities': [(0, 17, 'HP_CHAR')]}],\n",
       " ['Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.',\n",
       "  {'entities': [(0, 3, 'HP_CHAR'), (8, 20, 'HP_CHAR')]}],\n",
       " ['Mr. Dursley was the director of a firm called Grunnings, which made drills.',\n",
       "  {'entities': [(0, 11, 'HP_CHAR')]}],\n",
       " ['Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.',\n",
       "  {'entities': [(0, 12, 'HP_CHAR')]}]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train data\n",
    "\n",
    "#############\n",
    "#\n",
    "# The training data concists of the raw sentence as text and the position of all entities and there labels\n",
    "# Dudley is the son of Dursley. entities: [(0,7, 'HP_CHAR'), (21,27, 'HP_CHAR')] \n",
    "# 0----6...............21---27.\n",
    "#\n",
    "# TRAIN_DATA[(text, {\"entities\":[(start_entity, end_entity, label)]})]\n",
    "#\n",
    "# In this example we are only using the customized label 'HP_CHAR'. \n",
    "# In more complex models, there can also be multiple labels, the data structure would be the same.\n",
    "#\n",
    "##############\n",
    "\n",
    "from tqdm import tqdm\n",
    "train_data = []\n",
    "\n",
    "#loop over sentences\n",
    "for sentence in tqdm(hp_sentences_new):\n",
    "    # get and save entites per sentence\n",
    "    entities = []\n",
    "    for ent in sentence.ents:\n",
    "        entities.append( (ent.start_char, ent.end_char, ent.label_) )\n",
    "        \n",
    "    # if sentence doesn't contain any entities skip it\n",
    "    if len(entities)>0:\n",
    "        result = [sentence.text, {\"entities\": entities}]\n",
    "        train_data.append(result)\n",
    "        \n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckoss/miniconda3/envs/abd_workshop_2021/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "/home/ckoss/miniconda3/envs/abd_workshop_2021/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W034] Please install the package spacy-lookups-data in order to include the default lexeme normalization table for the language 'en'.\n",
      "  proc.begin_training(\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [02:27<1:11:07, 147.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 1343.4488567641315}\n",
      "Starting iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [05:02<1:10:50, 151.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 429.6318789849923}\n",
      "Starting iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [07:41<1:09:50, 155.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 321.8166859355644}\n",
      "Starting iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [10:16<1:07:16, 155.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 371.4937843162249}\n",
      "Starting iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [12:56<1:05:24, 156.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 271.7208533134708}\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [15:34<1:02:52, 157.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 286.43854036229544}\n",
      "Starting iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [18:13<1:00:32, 157.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 231.19553804370543}\n",
      "Starting iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [20:53<58:06, 158.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 177.20698522298508}\n",
      "Starting iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [24:11<59:48, 170.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 199.3591256304135}\n",
      "Starting iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [27:39<1:00:46, 182.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 212.03158236458927}\n",
      "Starting iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [31:06<1:00:09, 189.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 139.06240680536624}\n",
      "Starting iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [34:31<58:17, 194.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 154.96043161341953}\n",
      "Starting iteration 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [37:57<56:07, 198.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 194.7991615954541}\n",
      "Starting iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [41:24<53:28, 200.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 150.81754314918365}\n",
      "Starting iteration 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [45:06<51:47, 207.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 158.36678989770317}\n",
      "Starting iteration 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [49:10<50:52, 218.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 147.6767240298115}\n",
      "Starting iteration 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [53:16<49:06, 226.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 127.65077386526642}\n",
      "Starting iteration 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [57:50<48:09, 240.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 105.09673162892827}\n",
      "Starting iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [1:02:02<44:45, 244.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 132.0116254106755}\n",
      "Starting iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [1:06:10<40:54, 245.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 121.40402985431997}\n",
      "Starting iteration 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [1:10:17<36:52, 245.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 139.82463400002737}\n",
      "Starting iteration 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [1:14:25<32:52, 246.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 84.64178850856159}\n",
      "Starting iteration 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [1:18:42<29:06, 249.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 93.21968562463945}\n",
      "Starting iteration 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [1:23:19<25:47, 257.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 96.6871883819936}\n",
      "Starting iteration 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [1:28:09<22:16, 267.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 109.59376955643506}\n",
      "Starting iteration 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [1:33:03<18:21, 275.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 70.5665457706036}\n",
      "Starting iteration 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [1:37:45<13:52, 277.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 97.33595069507032}\n",
      "Starting iteration 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [1:43:07<09:41, 290.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 92.62564450873163}\n",
      "Starting iteration 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [1:48:46<05:05, 305.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 83.8828541889144}\n",
      "Starting iteration 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:54:22<00:00, 228.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 125.54900472928666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#training the actual model\n",
    "def train_spacy(data, iterations):\n",
    "    train_data = data\n",
    "    \n",
    "    # create a blank model\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        \n",
    "    # add entity labels to the new model\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    \n",
    "    # machine learning\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in tqdm(range(iterations)):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            for text, annotations in train_data:\n",
    "                nlp.update(\n",
    "                    [text],\n",
    "                    [annotations],\n",
    "                    drop = 0.2,\n",
    "                    sgd = optimizer,\n",
    "                    losses = losses\n",
    "                )\n",
    "            print(losses)\n",
    "    return nlp\n",
    "\n",
    "# run the model with 30 iterations\n",
    "#nlp= train_spacy(data = train_data, iterations = 30)\n",
    "\n",
    "# save the model disk for later reload\n",
    "#nlp.to_disk(\"hp_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dorsley HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "nlp = spacy.load('hp_ner_model')\n",
    "doc = nlp(\"\"\"Dorsley was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Dursley HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Mr. Dursley was the director of a firm called Grunnings, which made drills.\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomword HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "# <Randomword> is not in the corpus, but is also detected as HP_Char without any context\n",
    "# spacy learnt that this word may fit \"HP_CHAR\"\n",
    "# due the low training data we used and also only one label, most new words will be labeled by very low patterns\n",
    "\n",
    "doc = nlp(\"\"\"Randomword\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Randomwo\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)doc = nlp(\"\"\"Randomw\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomw HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Randomw\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rando HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Rando\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Rand\"\"\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in corpus\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    [char for char in final_characters if \"Rand\" in final_characters]\n",
    "except NameError:\n",
    "    print('not in corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry War HP_CHAR\n",
      "not in corpus\n"
     ]
    }
   ],
   "source": [
    "# So far our model learnt some a few patterns\n",
    "\n",
    "# alone the model doesn't recognize <War>\n",
    "doc = nlp(\"\"\"War\"\"\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# but in combination with <Harry> it is recognized as part of Harry\n",
    "doc = nlp(\"\"\"Harry War\"\"\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "# we can see that <Harry War> wasn't in the original data\n",
    "try:\n",
    "    [char for char in final_characters if \"Harry War\" in final_characters]\n",
    "except NameError:\n",
    "    print('not in corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry James HP_CHAR\n",
      "Potter HP_CHAR\n",
      "James HP_CHAR\n",
      "Lily Potter HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Neville Longbottom HP_CHAR\n",
      "Lord Voldemort HP_CHAR\n",
      "Voldemort HP_CHAR\n",
      "Severus Snape HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Dark Lord HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Voldemort HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Voldemort HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Who HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"\n",
    "Harry James Potter was an English half-blood wizard, and one of the most famous wizards of modern times. \n",
    "The only child and son of James and Lily Potter (née Evans), \n",
    "Harry's birth was overshadowed by a prophecy, \n",
    "naming either himself or Neville Longbottom as the one with the power to vanquish Lord Voldemort.\n",
    "After half of the prophecy was reported to Voldemort, courtesy of Severus Snape, Harry was chosen \n",
    "as the target due to his many similarities with the Dark Lord. In turn, this caused the Potter \n",
    "family to go into hiding. \n",
    "Voldemort made his first vain attempt to circumvent the prophecy when \n",
    "Harry was a year and three months old. During this attempt, he murdered \n",
    "Harry's parents as they tried to protect him, but this unsuccessful attempt to kill \n",
    "Harry led to Voldemort's first downfall. \n",
    "This downfall marked the end of the War, and to Harry henceforth being known as \"The Boy Who Lived\", as he was the only known survivor of the Killing Curse.\n",
    "\"\"\".replace('\\n',' ').strip() )\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter HP_CHAR\n",
      "THE BOY WHO LIVED HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Mrs. HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Most HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "You-Know-Who HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Shoo HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n",
      "Mrs. Dursley HP_CHAR\n",
      "Mrs. HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Mr. Dursley HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "for sentence in hp_sentences[:100]:\n",
    "    doc = nlp(sentence.text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Potter HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Uncle Vernon HP_CHAR\n",
      "Uncle Vernon HP_CHAR\n",
      "Aunt Petunia HP_CHAR\n",
      "Uncle Vernon HP_CHAR\n",
      "Dudley HP_CHAR\n",
      "Aunt Petunia HP_CHAR\n",
      "Uncle Vernon HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "for sentence in hp_sentences[900:920]:\n",
    "    doc = nlp(sentence.text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Ollivander HP_CHAR\n",
      "Try HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Ollivander HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Ollivander HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Ollivander HP_CHAR\n",
      "Not HP_CHAR\n",
      "Harry HP_CHAR\n",
      "Hagrid HP_CHAR\n",
      "Mr. HP_CHAR\n",
      "Ollivander HP_CHAR\n"
     ]
    }
   ],
   "source": [
    "for sentence in hp_sentences[2000:2020]:\n",
    "    doc = nlp(sentence.text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Material: 07 Generating Custom Word Vectors in Gensim (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model_name):\n",
    "    sentences = hp_sentences\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(\n",
    "        min_count = 5, # min freq of word\n",
    "        window = 2, # surrounding words of w2v\n",
    "        vector_size = 500 , # dimensionality of a token\n",
    "        sample = 6e-5,\n",
    "        alpha = 0.03,\n",
    "        min_alpha = 0.0007,\n",
    "        negative = 20,\n",
    "        workers = cores-1\n",
    "    )\n",
    "      \n",
    "    w2v_model.build_vocab(sentences)\n",
    "    w2v_model.train(sentences, total_examples = w2v_model.corpus_count, epochs=30)\n",
    "    w2v_model.save(f\"\"\"word_vectors/{model_name}.model\"\"\")\n",
    "    w2v_model.wv.save_word2vec_format(f\"\"\"word_vectors/word2vec_{model_name}.txt\"\"\")\n",
    "    \n",
    "training(\"hp_ner_model_01\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_similarity(word):\n",
    "    model = KeyedVectors.load_word2vec_format(\"word_vectors/word2vec_hp_ner_model_01.txt\", binary=False)\n",
    "    results = model.most_similar(positive=[word])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shouted', 0.9997987747192383), ('noticed', 0.9997981786727905), ('Theyre', 0.9997920393943787), ('For', 0.9997915625572205), ('turning', 0.9997914433479309), ('sharply', 0.9997906684875488), ('decided', 0.9997904896736145), ('Quirrell', 0.999790370464325), ('You', 0.9997897744178772), ('safely', 0.9997897148132324)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity(\"Harry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Slytherin', 0.9997866153717041), ('Theres', 0.9997844099998474), ('taken', 0.9997795224189758), ('points', 0.9997770190238953), ('If', 0.9997751712799072), ('Slytherins', 0.9997743368148804), ('place', 0.9997742772102356), ('So', 0.9997740983963013), ('warned', 0.9997740387916565), ('This', 0.9997732639312744)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity(\"Gryffindor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Material: 08 Importing Custom Word Vectors from Gensim into spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "word_vectors = \"word_vectors/word3vechp_ner_model_01.txt\"\n",
    "model_name = \"hp_model_test\"\n",
    "\n",
    "def load_word_vectors(model_name, word_vectors):\n",
    "    subprocess.run([sys.executable,\n",
    "                   \"-m\",\n",
    "                    \"spacy\",\n",
    "                   \"init-model\",\n",
    "                   \"en\",\n",
    "                   model_name,\n",
    "                   \"--vectors-loc\",\n",
    "                   word_vectors]\n",
    "    )\n",
    "load_word_vectors(model_name, word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:abd_workshop_2021]",
   "language": "python",
   "name": "conda-env-abd_workshop_2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
